# Custom-BPE-Tokenizer
# A custom tokenizer creation tool , leveraging Byte-Pair Encoding (BPE)

This repository provides a Byte-Pair Encoding (BPE) tokenizer that can be trained on any language dataset. it enables efficient tokenization and can be easily adapted for different scripts and languages.

# Features
* Custom BPE tokenization for any language.
* Fast and optimized using Hugging Faceâ€™s tokenizers.
* Scalable and adaptable for different linguistic datasets.
* Easy integration into NLP pipelines.

# Mandatory Prerequisite for this tool
# Text Corpus of Your Specific Language
* The dataset must be encoded in UTF-8 to handle special characters, diacritics, or unique scripts.
* It should contain natural, diverse, and large samples of text in the target language to ensure good tokenization

# Example Usage
This tokenizer was used to create a Santali (Olchiki script) tokenizer. Check out the implementation here: (https://github.com/rohitmahali01/Santali-Tokenizer/tree/main)
